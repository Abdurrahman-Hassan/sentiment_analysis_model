{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "623d643b-eb3e-452f-ac95-dbe68151aafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "df1=pd.read_csv(\"./1/twitter_training.csv\")\n",
    "\n",
    "#dataset1 = list(df1[[\"text\", \"value\"]].sample(frac=1).itertuples(index=False, name=None))\n",
    "dataset1=df1[[\"value\",\"text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "158e9b4e-0468-49ae-be3a-4fe999aa58c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2=pd.read_csv(\"./2/trainingdata.csv\", encoding=\"iso-8859-1\")\n",
    "df2.columns = [\"value\",\"somenumber\", \"date\", \"noquery\",\"user\",\"text\"]\n",
    "\n",
    "#trainingdata2=df2[[\"value\",\"text\"]]\n",
    "dataset2=df2[[\"value\",\"text\"]]\n",
    "\n",
    "#dataset2 = list(trainingdata2[[\"text\", \"value\"]].sample(frac=1).itertuples(index=False, name=None))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63215860-ee32-48cf-bab1-66e783235347",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_dataset1 = dataset1[dataset1['value'].str.isnumeric()]\n",
    "\n",
    "filtered_dataset2=dataset2\n",
    "# Convert 'value' column to integers\n",
    "filtered_dataset1.loc[:, 'value'] = filtered_dataset1['value'].astype(int)\n",
    "filtered_dataset2.loc[:, 'value'] = filtered_dataset2['value'].astype(int)\n",
    "\n",
    "# Filter rows with 'value' equal to 0, 2, or 4\n",
    "filtered_dataset1 = filtered_dataset1[filtered_dataset1['value'].isin([0, 2, 4])]\n",
    "filtered_dataset2 = filtered_dataset2[filtered_dataset2['value'].isin([0, 2, 4])]\n",
    "\n",
    "# Create datasets with selected columns\n",
    "train_dataset1 = list(filtered_dataset1[[\"text\", \"value\"]].sample(frac=1).itertuples(index=False, name=None))\n",
    "train_dataset2 = list(filtered_dataset2[[\"text\", \"value\"]].sample(frac=1).itertuples(index=False, name=None))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54937719-a032-4952-ba8e-b217846a9d8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combined_df=train_dataset1+train_dataset2\n",
    "\n",
    "#combined_df = pd.concat([modset1, modset2], axis=0)\n",
    "\n",
    "columns = [ 'text','value']\n",
    "\n",
    "training_df = pd.DataFrame(combined_df,columns=columns)\n",
    "\n",
    "training_dataset = list(training_df[[\"text\", \"value\"]].sample(frac=1).itertuples(index=False, name=None))\n",
    "\n",
    "#print(len(training_dataset))\n",
    "\n",
    "#1674672 = 74673 + 1599998"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a074306-843d-412f-bdcf-09aaf781b9f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "train_doc_data=[]\n",
    "for text, value in training_dataset:\n",
    "    if isinstance(text, str) and isinstance(value, int):\n",
    "        cleaned_text = re.sub(r'[^A-Za-z0-9\\s]', '', text)    \n",
    "        doc = nlp(cleaned_text)\n",
    "        train_doc_data.append((doc, value))\n",
    "\n",
    "#7sec (en_web)=1000\n",
    "#159sec (en)=1.7million"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "051cf9e8-548e-40c0-ba2a-9af98e68ff04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=pd.read_csv(\"./1/twitter_validation.csv\")\n",
    "df4=pd.read_csv(\"./2/testdata.csv\", encoding=\"iso-8859-1\")\n",
    "\n",
    "df3.columns = [\"random\",\"org\", \"value\", \"text\"]\n",
    "#df4.columns = [\"value\",\"somenumber\", \"date\", \"noquery\",\"user\",\"text\"]\n",
    "\n",
    "trainingdata3=df3[[\"value\",\"text\"]]\n",
    "\n",
    "df4.columns = [\"value\",\"somenumber\", \"date\", \"noquery\",\"user\",\"text\"]\n",
    "\n",
    "trainingdata4=df4[[\"value\",\"text\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7602b6d7-55a3-4c3a-8ce4-9b06ca384d9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdur\\AppData\\Local\\Temp\\ipykernel_3824\\411516550.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_dataset4['value'] = filtered_dataset4['value'].astype(int)\n"
     ]
    }
   ],
   "source": [
    "filtered_dataset3 = trainingdata3[trainingdata3['value'].str.isnumeric()]\n",
    "filtered_dataset4=trainingdata4\n",
    "# Convert 'value' column to integers\n",
    "filtered_dataset3.loc[:, 'value'] = filtered_dataset3['value'].astype(int)\n",
    "filtered_dataset4['value'] = filtered_dataset4['value'].astype(int)\n",
    "\n",
    "# Filter rows with 'value' equal to 0, 2, or 4\n",
    "filtered_dataset3 = filtered_dataset3[filtered_dataset3['value'].isin([0, 2, 4])]\n",
    "filtered_dataset4 = filtered_dataset4[filtered_dataset4['value'].isin([0, 2, 4])]\n",
    "\n",
    "# Create datasets with selected columns\n",
    "dataset3 = list(filtered_dataset3[[\"text\", \"value\"]].sample(frac=1).itertuples(index=False, name=None))\n",
    "dataset4 = list(filtered_dataset4[[\"text\", \"value\"]].sample(frac=1).itertuples(index=False, name=None))\n",
    "\n",
    "# Combine the two datasets\n",
    "#test_combined_df = dataset3 + dataset4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abddbb3c-6d60-4a8f-937c-28afd5761186",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset3 = list(trainingdata3[[\"text\", \"value\"]].sample(frac=1).itertuples(index=False, name=None))\n",
    "#dataset4 = list(trainingdata4[[\"text\", \"value\"]].sample(frac=1).itertuples(index=False, name=None))\n",
    "\n",
    "test_combined_df=dataset3+dataset4\n",
    "\n",
    "#print(combined_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4344fcbe-8891-4b5c-ab8e-117661f518db",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [ 'text','value']\n",
    "testing_df = pd.DataFrame(test_combined_df,columns=columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27e94e25-9d0c-4d6d-b7dd-cc9e37e53d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_dataset = list(testing_df[[\"text\", \"value\"]].sample(frac=1).itertuples(index=False, name=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a6fbe53-bb1b-43f6-880e-74c453f6b9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_doc_data = []\n",
    "for text, value in testing_dataset:\n",
    "    if isinstance(text, str) and isinstance(value, int):\n",
    "        cleaned_test_text = re.sub(r'[^A-Za-z0-9\\s]', '', text)    \n",
    "        doc = nlp(cleaned_test_text)\n",
    "        testing_doc_data.append((doc, value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a603e47e-c530-4e29-a3aa-b2353ae7bb96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import spacy\n",
    "from spacy.lang.pt.stop_words import STOP_WORDS\n",
    "\n",
    "def preprocessing(text):\n",
    "  text = text.lower()\n",
    "  \n",
    "  tokens = [token.text for token in nlp(text)]\n",
    "  \n",
    "  tokens = [t for t in tokens if \n",
    "              t not in STOP_WORDS and \n",
    "              t not in string.punctuation and \n",
    "              len(t) > 3]\n",
    "  \n",
    "  tokens = [t for t in tokens if not t.isdigit()]\n",
    "    \n",
    "  return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ffcafe93-8082-4945-bcb0-d1936aef37d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def convert(data, outfile):\n",
    "    db = spacy.tokens.DocBin()\n",
    "    docs = []\n",
    "    for doc, value in nlp.pipe(data, as_tuples=True):\n",
    "        doc.cats[\"Negative\"] = value == 0\n",
    "        doc.cats[\"Neutral\"] = value == 2\n",
    "        doc.cats[\"Positive\"] = value == 4\n",
    "        db.add(doc)\n",
    "    \n",
    "    db.to_disk(outfile)\n",
    "\n",
    "#print(len(train_doc_data[:830560]))\n",
    "#print(len(testing_doc_data))\n",
    "convert(train_doc_data[:830560], \"./train.spacy\")\n",
    "convert(testing_doc_data, \"./dev.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e096ecfc-3e57-483f-a727-c79e223dbba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;3m[!] To generate a more effective transformer-based config (GPU-only),\n",
      "install the spacy-transformers package and re-run this command. The config\n",
      "generated now does not use transformers.\u001b[0m\n",
      "\u001b[38;5;4m[i] Generated config template specific for your use case\u001b[0m\n",
      "- Language: pt\n",
      "- Pipeline: textcat\n",
      "- Optimize for: efficiency\n",
      "- Hardware: CPU\n",
      "- Transformer: None\n",
      "\u001b[38;5;2m[+] Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m[+] Saved config\u001b[0m\n",
      "config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init config  --lang pt --pipeline textcat --optimize efficiency --force config.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "195a4078-2b0d-4a4c-af34-3bb28a086c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73ce33d-eb18-4a27-be6e-53f8f9da6e0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
